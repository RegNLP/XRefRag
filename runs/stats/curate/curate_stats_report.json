{
  "generated_at": "2026-01-26T03:56:12.514774",
  "datasets": {
    "ukfin": {
      "total_items": 44,
      "pass_qp_count": 41,
      "drop_qp_count": 3,
      "low_consensus_count": 4,
      "avg_confidence_mean": 0.822,
      "avg_weighted_fraction": 1.0,
      "reason_code_breakdown": {
        "QP_WRONG_TARGET": 3
      },
      "judge_model": "gpt-5.2-MBZUAI",
      "judge_temperature": 0.0,
      "num_judge_passes": 1,
      "input_file": "runs/curate_ukfin/out/curated_items.judge.jsonl",
      "timestamp": "2026-01-26T03:30:26",
      "passage_stats": {
        "avg_source_length": 351.3863636363636,
        "avg_target_length": 272.8636363636364,
        "min_source_length": 58,
        "min_target_length": 82,
        "max_source_length": 879,
        "max_target_length": 745
      }
    },
    "adgm": {
      "total_items": 79,
      "pass_qp_count": 77,
      "drop_qp_count": 2,
      "low_consensus_count": 0,
      "avg_confidence_mean": 0.87,
      "avg_weighted_fraction": 1.0,
      "reason_code_breakdown": {
        "QP_WRONG_TARGET": 2
      },
      "judge_model": "gpt-5.2-MBZUAI",
      "judge_temperature": 0.0,
      "num_judge_passes": 1,
      "input_file": "runs/curate_adgm/out/curated_items.judge.jsonl",
      "timestamp": "2026-01-26T03:51:19",
      "passage_stats": {
        "avg_source_length": 403.65822784810126,
        "avg_target_length": 653.4556962025316,
        "min_source_length": 82,
        "min_target_length": 103,
        "max_source_length": 1154,
        "max_target_length": 3968
      }
    }
  }
}
